# ğŸ§  Spring AI + Ollama Backend (Gemma 2B Integration)

This is a Spring Boot backend that connects to **Ollama** to run **local AI models** like `gemma:2b` using **Spring AI 1.0.0**.  
It exposes a simple REST API to send prompts and get smart AI responses â€” 100% offline and private.

---

ğŸš€ Features

- ğŸ”— Spring Boot 3.5.x
- ğŸ¤– Spring AI 1.0.0 integration
- ğŸ§© Works with local LLMs via Ollama (Gemma, Phi-3, LLaMA3, etc.)
- ğŸ’¬ REST API endpoint to send prompts
- âš™ï¸ Easily swappable models via `application.properties`

---

ğŸ“¦ Requirements

- Java 22
- Maven
- [Ollama installed](https://ollama.com/download) (on Windows/Linux/Mac)
- A model like `gemma:2b` or `phi3:mini` pulled via Ollama

---

âš™ï¸ API Usage

### POST `/ai/ask`

**Request Body:**
```json
{
  "prompt": "What is Spring Boot?"
}

